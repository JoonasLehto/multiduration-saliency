{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from keras.layers import Input, TimeDistributed, Lambda, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras.utils import Sequence\n",
    "from keras.optimizers import Adam\n",
    "import cv2\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "import scipy.io\n",
    "from copy import deepcopy\n",
    "import tqdm \n",
    "import math\n",
    "import random\n",
    "\n",
    "sys.path.append('src')\n",
    "\n",
    "from data_loading import load_datasets_multiduration\n",
    "from util import get_model_by_name, create_losses\n",
    "\n",
    "from eval import *\n",
    "# from attentive_convlstm_new import AttentiveConvLSTM2D\n",
    "# from dcn_resnet_new import dcn_resnet\n",
    "# from gaussian_prior_new import LearningPrior\n",
    "# from losses_keras2 import *\n",
    "from sal_imp_utilities import *\n",
    "from cb import InteractivePlot\n",
    "from losses_keras2 import loss_wrapper\n",
    "# #from multiduration_models import xception_3stream\n",
    "# from multiduration_models import sam_xception_timedist, sam_resnet_timedist, xception_se_lstm\n",
    "# from util import get_model_by_name\n",
    "\n",
    "# from data_loading import load_datasets_multiduration, load_datasets_sal_imp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check GPU status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THESE IN \n",
    "dataset = \"codecharts\"\n",
    "bp = \"/mnt/localssd2/predimportance/predimportance_shared/datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [500, 3000, 5000]\n",
    "\n",
    "data = load_datasets_multiduration(dataset, times, bp=bp, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THESE IN: set training parameters \n",
    "ckpt_savedir = \"/data/vision/oliva/scratch/anelise/predimportance/models/ckpt/sammd_cc_clean/\"\n",
    "\n",
    "# train\n",
    "load_weights = False\n",
    "# md-sem trained on salicon-md. Fine tune this on new code charts w/ccm. \n",
    "weightspath = \"/mnt/localssd2/predimportance/predimportance_shared/models/ckpt/xception_se_lstm/xception_se_lstm_salicon_md_fixations_3match10kl-5cc-1nss_ep04_valloss-2.2668.hdf5\"\n",
    "#weightspath = \"/data/vision/oliva/scratch/anelise/predimportance/models/ckpt/sam_resnet_salmd/salicon_md_fixations_6bc4kl-3cc-10nss_ep01_valloss-20.3203.hdf5\"\n",
    "\n",
    "batch_size = 8\n",
    "init_lr = 0.00001\n",
    "lr_reduce_by = .1\n",
    "reduce_at_epoch = 2\n",
    "n_epochs = 15\n",
    "\n",
    "opt = Adam(lr=init_lr) \n",
    "\n",
    "# losses is a dictionary mapping loss names to weights \n",
    "losses = {\n",
    "     'kl': 10,\n",
    "     'cc': -5,\n",
    "     'nss': -1,\n",
    "     'ccmatch': 3\n",
    "}\n",
    "\n",
    "model_name = \"md-sem\"\n",
    "model_inp_size = (240, 320)\n",
    "model_out_size = (480, 640)\n",
    "n_timesteps = len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model \n",
    "model_params = {\n",
    "    'input_shape': model_inp_size + (3,),\n",
    "    'n_outs': len(losses),\n",
    "    'nb_timestep': n_timesteps\n",
    "}\n",
    "model_func, mode = get_model_by_name(model_name)\n",
    "model = model_func(**model_params)\n",
    "\n",
    "if load_weights: \n",
    "    model.load_weights(weightspath)\n",
    "    print(\"Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data generation and checkpoints\n",
    "if not os.path.exists(ckpt_savedir): \n",
    "    os.makedirs(ckpt_savedir)\n",
    "    \n",
    "# sort the losses so that those that use a fixmap are last, by convention\n",
    "l, lw, l_str, n_heatmaps = create_losses(losses, model_out_size)\n",
    "n_fixmaps = len(l) - n_heatmaps\n",
    "print(\"Loss string\", l_str)\n",
    "    \n",
    "# Generators\n",
    "gen_train = MultidurationGenerator(\n",
    "                img_filenames=data['img_files_train'], \n",
    "                map_filenames=data['map_files_train'], \n",
    "                fix_filenames=data['fix_files_train'], \n",
    "                batch_size=batch_size, \n",
    "                mode=mode,\n",
    "                img_size=model_inp_size, \n",
    "                map_size=model_out_size,\n",
    "                shuffle=True, \n",
    "                augment=False, \n",
    "                n_output_maps=n_heatmaps,\n",
    "                n_output_fixs=n_fixmaps,\n",
    "                fix_as_mat=data.get('fix_as_mat', False),\n",
    "                fix_key=data.get('fix_key', ''))\n",
    "\n",
    "gen_val = MultidurationGenerator(\n",
    "            img_filenames=data['img_files_val'], \n",
    "            map_filenames=data['map_files_val'], \n",
    "            fix_filenames=data['fix_files_val'], \n",
    "            batch_size=1, \n",
    "            mode=mode,\n",
    "            img_size=model_inp_size, \n",
    "            map_size=model_out_size,\n",
    "            shuffle=False, \n",
    "            augment=False, \n",
    "            n_output_maps=n_heatmaps,\n",
    "            n_output_fixs=n_fixmaps,\n",
    "            fix_as_mat=data.get('fix_as_mat', False),\n",
    "            fix_key=data.get('fix_key', '')\n",
    "        )\n",
    "\n",
    "# Callbacks\n",
    "\n",
    "# where to save checkpoints\n",
    "filepath = os.path.join(ckpt_savedir, dataset + \"_\" + l_str + '_ep{epoch:02d}_valloss{val_loss:.4f}.hdf5')\n",
    "print(\"Checkpoints will be saved with format %s\" % filepath)\n",
    "\n",
    "cb_chk = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=True, period=1)\n",
    "cb_plot = InteractivePlot()\n",
    "\n",
    "def step_decay(epoch):\n",
    "    lrate = init_lr * math.pow(lr_reduce_by, math.floor((1+epoch)/reduce_at_epoch))\n",
    "    if epoch%reduce_at_epoch:\n",
    "        print('Reducing lr. New lr is:', lrate)\n",
    "    return lrate\n",
    "cb_sched = LearningRateScheduler(step_decay)\n",
    "\n",
    "cbs = [cb_chk, cb_sched, cb_plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the generator \n",
    "img, outs = gen_train.__getitem__(1)\n",
    "print(\"batch size: %d. Num inputs: %d. Num outputs: %d.\" % (batch_size, len(img), len(outs)))\n",
    "print(outs[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss=l, loss_weights=lw)\n",
    "\n",
    "print('Ready to train')\n",
    "model.fit_generator(gen_train, epochs=n_epochs, verbose=1, callbacks=cbs, validation_data=gen_val, max_queue_size=10,  workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN\n",
    "load_ckpt = True\n",
    "# md-sem on code charts (full split) \n",
    "#W_eval = \"/mnt/localssd2/predimportance/predimportance_shared/models/ckpt/xception_se_lstm/xception_se_lstm_codecharts0_3match10kl-5cc-1nss_ep03_valloss-0.7587.hdf5\"\n",
    "#W_eval = \"/data/vision/oliva/scratch/anelise/predimportance/models/ckpt/mdsem_cc_clean/codecharts_kl10cc-5nss-1ccmatch3_ep04_valloss-0.0789.hdf5\"\n",
    "# W_eval = \"/data/vision/oliva/scratch/anelise/predimportance/models/ckpt/sammd_cc_clean/codecharts_kl10ccmatch3cc-5nss-1_ep08_valloss0.2516.hdf5\"\n",
    "W_eval = \"/mnt/localssd2/predimportance/predimportance_shared/models/ckpt/xception_se_lstm/xception_se_lstm_codecharts0_3match10kl-5cc-1nss_ep04_valloss-0.7401.hdf5\"\n",
    "blur_sigma = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_ckpt: \n",
    "    model.load_weights(W_eval)\n",
    "    print(\"Loaded weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = eval_generator(\n",
    "    data['img_files_test'], \n",
    "    data['map_files_test'],\n",
    "    data['fix_files_test'], \n",
    "    None, \n",
    "    inp_size=model_inp_size,\n",
    "    fix_as_mat=data.get('fix_as_mat', False),\n",
    "    fix_key=data.get('fix_key', ''), \n",
    ")\n",
    "#get_stats(model, gen, blur=True, mode='simple', n=False, imsize=(480, 620))\n",
    "get_stats_multiduration(model, gen, blur=blur_sigma, mode=mode, start_at=None, n_times=len(times), compare_across_times=False)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_path_test = \"/mnt/localssd2/predimportance/predimportance_shared/datasets/cat2000/testStimuli/\"\n",
    "savedir = \"../models/pred/mdsem_mit1003/mit1003_6bc4kl-3cc-10nss_ep12_valloss-28.7681/\"\n",
    "predict_and_save(model, img_files_test, inp_size=(shape_r, shape_c), savedir=savedir, blur=7, test_img_base_path=\"\", ext=\"jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(\"/mnt/localssd2/predimportance/predimportance_shared/models/ckpt/xception_se_lstm/xception_se_lstm_codecharts0_3match10kl-5cc-1nss_ep03_valloss-0.7587.hdf5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = eval_generator(\n",
    "    data['img_files_test'], \n",
    "    data['map_files_test'],\n",
    "    data['fix_files_test'], \n",
    "    None, \n",
    "    inp_size=model_inp_size,\n",
    "    fix_as_mat=data.get('fix_as_mat', False),\n",
    "    fix_key=data.get('fix_key', ''), \n",
    "    return_name=True\n",
    ")\n",
    "# idxs= [10,11] #list(range(len(gen_val)))\n",
    "# gen_val.return_names=True\n",
    "\n",
    "\n",
    "for i, elt in enumerate(gen):\n",
    "    images, maps, _, _, name = elt\n",
    "    #images, maps, names = gen_val.__getitem__(idd) #np.random.randint(len(gen_val)))\n",
    "    preds = model.predict(images[0])\n",
    "    \n",
    "    fig = plt.figure(figsize=[13,10])\n",
    "    for t in range(preds[0].shape[1]):\n",
    "        plt.subplot(3,3,t*3+1)\n",
    "        #print(\"images[t] shape\", np.squeeze(images[t]).shape)\n",
    "        im = reverse_preprocess(np.squeeze(images[t]))\n",
    "        plt.imshow(im)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "#             plt.title('Original')\n",
    "        plt.subplot(3,3,t*3+2)\n",
    "        plt.imshow(maps[t])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "#             plt.title('Gr Truth Imp')\n",
    "        plt.subplot(3,3,t*3+3)\n",
    "        p = preds[0][0,t,:,:,0]\n",
    "        plt.imshow(p)\n",
    "        p_norm = (p-np.min(p))/(np.max(p)-np.min(p))\n",
    "#             p_img = p_norm*255\n",
    "#             pred_img = Image.fromarray(np.uint8(p_img), \"L\")\n",
    "#             pred_img.save('../../predimportance/models/pred/',model_func.__name__,W.split('/')[-1][:-5],times[t],names[i].split('/')[-1])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "#             plt.title('Predicted Imp')\n",
    "        plt.tight_layout()\n",
    "    #plt.show()\n",
    "    name = name.split(\"/\")[-1]\n",
    "    print(name)\n",
    "    fig.savefig(\"/data/vision/oliva/scratch/anelise/predimportance/models/fig/mdsem_cc0/\" + name)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mdsem = get_model_by_name(\"md-sem\")[0](**model_params)\n",
    "model_sam_onedur = get_model_by_name(\"sam-resnet\")[0](**model_params)\n",
    "model_sam = get_model_by_name(\"sam-md\")[0](**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_mdsem_to_sam_md_and_samx3(ckpt_mdsem, ckpt_sam_md, ckpts_sam_x3, img_names, gr_truths, model_mdsem, model_sam, model_sam_onedur,times=[500,3000,5000]):\n",
    "    preds_x3 = {}\n",
    "    shape_r, shape_c = model_inp_size\n",
    "    images = preprocess_images(img_names, shape_r, shape_c)\n",
    "    gr_truth = preprocess_maps(gr_truths, shape_r, shape_c)\n",
    "    c=0\n",
    "    for t,ckpt in ckpts_sam_x3.items():\n",
    "        print('CKPT for time %d' % t)\n",
    "        model_sam_onedur.load_weights(ckpt)\n",
    "        preds_x3[c] = model_sam_onedur.predict(images)\n",
    "        c+=1\n",
    "#         print('preds[t].shape (should be (4,r,c,1))',preds[t].shape)\n",
    "    model_sam.load_weights(ckpt_sam_md)\n",
    "    preds_sam_md = model_sam.predict(images)\n",
    "    \n",
    "    model_mdsem.load_weights(ckpt_mdsem)\n",
    "    preds_mdsem = model_mdsem.predict(images)\n",
    "    \n",
    "    for i in range(len(img_names)):\n",
    "        print(img_names[i])\n",
    "        plt.figure(figsize = (14,8))\n",
    "        # Plot maps for each timestep\n",
    "        for t in range(3):\n",
    "            plt.subplot(3,5,t*5+1)\n",
    "            plt.imshow(reverse_preprocess(images[i]))\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.title('Original image')\n",
    "            plt.subplot(3,5,t*5+2)\n",
    "            plt.imshow(gr_truth[i,:,:,0])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.title('Ground truth')\n",
    "            plt.subplot(3,5,t*5+3)\n",
    "#             print(len(preds_x3[t],preds_x3[t][0].shape)\n",
    "            plt.imshow(preds_x3[t][0][i,:,:,0])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.title('SAM x3')\n",
    "            plt.subplot(3,5,t*5+4)\n",
    "            plt.imshow(preds_sam_md[0][i,t,:,:,0])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.title('SAM-MD')\n",
    "            ax = plt.subplot(3,5,t*5+5)\n",
    "            plt.imshow(preds_mdsem[0][i,t,:,:,0])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.title('MD-SEM')\n",
    "            plt.ylabel(str(times[t])+'ms')\n",
    "            ax.yaxis.set_label_position(\"right\")\n",
    "            \n",
    "ckpts_sam_x3 = {\n",
    "    500:'/data/vision/oliva/scratch/anelise/predimportance/models/ckpt/sam_resnet_cc/codecharts500_nss-1kl10cc-5_ep11_valloss-2.3949.hdf5', \n",
    "    3000: '/data/vision/oliva/scratch/anelise/predimportance/models/ckpt/sam_resnet_cc/codecharts3000_nss-1kl10cc-5_ep06_valloss1.6970.hdf5',\n",
    "    5000: '/data/vision/oliva/scratch/anelise/predimportance/models/ckpt/sam_resnet_cc/codecharts5000_nss-1kl10cc-5_ep13_valloss2.4631.hdf5',\n",
    "}\n",
    "\n",
    "ckpt_mdsem = '/mnt/localssd2/predimportance/predimportance_shared/models/ckpt/xception_se_lstm/xception_se_lstm_codecharts0_3match10kl-5cc-1nss_ep03_valloss-0.7587.hdf5'\n",
    "ckpt_sam_md = \"/data/vision/oliva/scratch/anelise/predimportance/models/ckpt/sammd_cc_clean/codecharts_kl10ccmatch3cc-5nss-1_ep08_valloss0.2516.hdf5\"\n",
    "\n",
    "\n",
    "imgs = ['/data/vision/oliva/scratch/code-chart-data/training_data/salicon_md/val/raw_img/COCO_val2014_000000043561.jpg',\n",
    "       '/data/vision/oliva/scratch/code-chart-data/training_data/salicon_md/val/raw_img/COCO_val2014_000000036810.jpg',\n",
    "       '/data/vision/oliva/scratch/code-chart-data/training_data/salicon_md/val/raw_img/COCO_val2014_000000043851.jpg',\n",
    "       '/data/vision/oliva/scratch/code-chart-data/training_data/salicon_md/val/raw_img/COCO_val2014_000000023807.jpg']\n",
    "\n",
    "bp = '/data/vision/oliva/scratch/code-chart-data/training_data/salicon_md_fixations/val/raw_img/'\n",
    "bp_gr = '/data/vision/oliva/scratch/code-chart-data/training_data/salicon_md_fixations/val/heatmaps/'\n",
    "imgs = sorted([os.path.join(bp, f) for f in os.listdir(bp)])[:10]\n",
    "gr_truths = sorted([os.path.join(bp_gr, f) for f in os.listdir(bp_gr)])[:10]\n",
    "\n",
    "compare_mdsem_to_sam_md_and_samx3(ckpt_mdsem, ckpt_sam_md, ckpts_sam_x3, imgs, gr_truths, model_mdsem, model_sam, model_sam_onedur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
